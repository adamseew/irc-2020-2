Energy-Sensitive Vision-Based Autonomous Tracking and Landing of a UAV

Georgios Zamanakos, Adam Seewald, Henrik Skov Midtiby, and Ulrik Pagh Schultz

In this paper we present a robust, vision-based algorithm for
autonomous tracking and landing on a moving platform in varying
environmental conditions. We use a novel landing marker robust to
occlusions to track the moving platform and the YOLOv3-tiny CNN to
detect ground-based hazards in an agricultural use case. We perform
all computations on-board using an Nvidia Jetson Nano and analyse the
impact on the flight time by profiling the energy consumption of the
landing marker detection algorithm and YOLOv3-tiny CNN.  Experiments
are conducted in Gazebo simulation using the powprofiler energy
modeling tool to measure the energy cost as a function of Quality of
Service (QoS).

Our experiments test the energy efficiency and robustness of our
system in various dynamic wind disturbances.  We show that the landing
marker detection algorithm can be run at the highest QoS with only a
marginal energy overhead whereas adapting the QoS level of YOLOv3-tiny
CNN results in a considerable power saving for the system as a
whole. The power saving is significant for a system executing on a
fixed-wind UAV but only marginal if executing on a standard multirotor
UAV.
